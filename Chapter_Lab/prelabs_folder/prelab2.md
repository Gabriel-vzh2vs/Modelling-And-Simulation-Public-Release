(prelab-2)=
# Pre-Lab 2: Tutorial for Monte Carlo Methods (Do)

This pre-lab uses XLrisk (for Excel users) and pyMC + pandas packages (for Python Users)
as the main implementation methods; however, these all of these tasks can be
done within other packages in python such as the monaco and (copulas or statsmodels) packages.

In this pre-lab we will discuss the Monte Carlo Method with its implementations
and do a short example of coin-flipping that loosely relates to Lab-2. Keep in mind that
the XLRisk and pyMC sections are almost identical on purpose.

::::{tab-set}

### Correlations between distributions (Copula)

In this pre-lab, we consider copulas as forcing a distribution to assume the
behavior of another one, this is known as correlation. An example of this would be if a person goes to an
expensive hotel, it is more likely that they would get expensive food, tours, and everything else on their trip.

In more formal terms, based on Sklar's Theorem, a copula is a multivariate distribution such that marginalizing gives
a uniform $[0,1]$, and the marginal distributions are inherently uncorrelated with other, and the correlation is
exclusively provided by the copula; here is an example of a gaussian copula from a completed {ref}`project-1`.

```{figure} #fig:copula
:label: fig:copula-1

An example of the correlation between Accommodation Prices and Meal Costs through a Correlation Matrix,
this is related to {ref}`project-1`.

```

:::{tab-item} XLRisk

### Functions

In XLRisk, there is a series of functions for defining a random variate, of which the bare
minimum for this pre-lab are here, with a more extensive list in {ref}`sec:software`.

- =RiskBernolli() # For a Bernoulli Variate
- =RiskUniform() # For a Uniform Variate
- =RiskCorMat() # For Copulas

In XLrisk, this behavior is implemented through the function RiskCorMat, which takes a matrix and applies it to
random variates generated by XLRisk based on user parameters.

### Trials

a

### Results

b

### Skew and Kurtosis

c

### Walk-Through

d

:::

:::{tab-item} pyMC + Numpy + Scipy

### pyMC Functions

See {ref}`sec:software` for specifics on what might be useful for
pyMC, as it uses Numpy and Scipy functions to perform actions, and
some PyMC functions are included toward the end of the document.

### pyMC Forced Correlations

In pyMC, copulas are implemented through a five step process based on
{cite}`PyMCDocumentation`:

1. Define the marginal distributions (they can be any distribution that is univariate);
2. Transform the marginals into the inverse of the Gaussian CDF (this is known as the Probability integral transform).
3. Define the multivariate Gaussian instantiated with the desired correlation matrix between the marginals;
4. Then simulate (or obtain the actual values from) a multidimensional Gaussian.
5. Apply the probability integral transformation to the multidimensional Gaussian.
6. Replace the marginals of the multidimensional Gaussian into the desired marginal distributions from step 2.

An example of this transformation between two exponential random variables with parameters three and five is included below:

```{code} python
import matplotlib.pyplot as plt
import numpy as np
import pymc as pm
import seaborn as sns

from scipy.stats import expon, multivariate_normal, norm

# Step 3, define the multivariate Gaussian:
b_scale = 2
θ = {"a_dist": norm(), "b_dist": expon(scale=1 / b_scale), "rho": 0.9}

n_samples = 5000

# Step 4: sample the multivariate Gaussian:
mu = [0, 0]
cov = [[1, θ["rho"]], [θ["rho"], 1]]
x = multivariate_normal(mu, cov).rvs(n_samples, random_state=rng)
a_norm = x[:, 0]
b_norm = x[:, 1]

# Step 5: Apply the Transformation to the multivariate Gaussian:
a_unif = norm(loc=0, scale=1).cdf(a_norm)
b_unif = norm(loc=0, scale=1).cdf(b_norm)
sns.jointplot(x=a_unif, y=b_unif, height=6, kind="hex");

# 
a1 = ["a_dist"].cdf(a)
b1 = ["b_dist"].cdf(b)
sns.jointplot(x=a1, y=b1, kind="hex", height=6);

```

### pyMC Trials



### pyMC Presentation of Results

### Skew and Kurtosis through Pandas

### Example of Using pyMC (Walk-through)



:::

::::
